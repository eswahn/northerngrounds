{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Workshop - GAN training.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ikWAQfur-3Au"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "1QqmG3J6c_6-X6PeLJuS9vLue-GdMgKl2",
      "authorship_tag": "ABX9TyOUuHtyasEOg+wHtv2pafOF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eswahn/northerngrounds/blob/main/Workshop_GAN_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQC9VoBOiDcZ"
      },
      "source": [
        "# Install StyleGAN2-ADA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKYAU7Wub3WW"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!git clone https://github.com/eswahn/stylegan2-ada\n",
        "%cd stylegan2-ada\n",
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11dpSBJWiHSM"
      },
      "source": [
        "# Set training data\r\n",
        "Set the correct path to your images below or upload them manually to /content/stylegan2-ada/images.\r\n",
        "\r\n",
        "Mount Google Drive and set the correct output path if you want your results to be saved there.\r\n",
        "\r\n",
        "Run the cell below when your settings are correct."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2siM7AaO58_s",
        "cellView": "form"
      },
      "source": [
        "#@markdown Paths\r\n",
        "data_path = '/content/drive/MyDrive/Data/northerngrounds/axos.zip' #@param {type:\"string\"}\r\n",
        "output_path = '/content/drive/MyDrive/Output/stylegan2-ada/' #@param {type:\"string\"}\r\n",
        "#@markdown Image resolution\r\n",
        "resolution = \"512\" #@param [512, 1024]\r\n",
        "#@markdown If no previous checkpoint exists:\r\n",
        "train_from = \"wikiart model\" #@param [\"scratch\", \"wikiart model\", \"ffhq faces model\"] {type:\"string\"}\r\n",
        "#@markdown After how many ticks should model snapshots and output images be saved?\r\n",
        "snapshot_count = 4 #@param {type:'integer'}\r\n",
        "imgsnapshot_count =  1#@param {type:'integer'}\r\n",
        "#@markdown Allow training data to be mirrored during training?\r\n",
        "mirroredX = True #@param {type:\"boolean\"}\r\n",
        "mirroredY = False #@param {type:\"boolean\"}\r\n",
        "\r\n",
        "if train_from == 'wikiart model':\r\n",
        "  if resolution == '512':\r\n",
        "    !gdown --id 1HmJ2URt1WrTVvjQkhsAuR8I4UvmxreNH -O /content/wikiart.pkl\r\n",
        "  if resolution == '1024':\r\n",
        "    !gdown --id 1_GYAYJJLK_LebYZaEiSfHUWeU67VWeal -O /content/wikiart.pkl\r\n",
        "  transfer_from = '/content/wikiart.pkl' # False: train from scratch, otherwise do tranfer learning\r\n",
        "\r\n",
        "if train_from == 'ffhq face model':\r\n",
        "  transfer_from = 'ffhq%i' % resolution\r\n",
        "\r\n",
        "if train_from == 'scratch':\r\n",
        "  transfer_from = False\r\n",
        "\r\n",
        "!rm -rf /content/stylegan2-ada/images /content/stylegan2-ada/datasets\r\n",
        "!mkdir /content/stylegan2-ada/images /content/stylegan2-ada/datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikWAQfur-3Au"
      },
      "source": [
        "# Load training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBs7zW9ZPVhi",
        "outputId": "26922528-0790-4cdb-a48c-8722df950b46"
      },
      "source": [
        "import glob, os, pathlib\r\n",
        "\r\n",
        "%cd /content/stylegan2-ada\r\n",
        "\r\n",
        "dataset_name = os.path.basename(data_path)\r\n",
        "images_path = '/content/stylegan2-ada/images/'\r\n",
        "\r\n",
        "if '.' in dataset_name:\r\n",
        "  dataset_name = dataset_name[:dataset_name.find('.')]\r\n",
        "\r\n",
        "if os.path.exists(data_path):\r\n",
        "  print('Using training set from %s' % data_path)\r\n",
        "  %cd {images_path}\r\n",
        "  if '.zip' in data_path:                       # zip archive\r\n",
        "    !cp -a {data_path} {images_path}\r\n",
        "    !unzip -qq *.zip\r\n",
        "    !rm -rf *.zip\r\n",
        "  elif '.tar.gz' in data_path:                  # .tar.gz archive\r\n",
        "    !cp -a {data_path} {images_path}\r\n",
        "    !tar -zxf *.tar.gz\r\n",
        "    !rm -rf *.tar.gz\r\n",
        "  else:                                         # directory\r\n",
        "    !cp -a {data_path} {images_path}\r\n",
        "#    images_path = data_path\r\n",
        "else:\r\n",
        "  print('Training set not found')\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/stylegan2-ada\n",
            "Using training set from /content/drive/MyDrive/Data/northerngrounds/axos.zip\n",
            "/content/stylegan2-ada/images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTQ5qOJ0CQeT"
      },
      "source": [
        "%cd /content/stylegan2-ada\r\n",
        "!python dataset_tool.py create_from_images ./datasets/{dataset_name} images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VVmDBUBim1O"
      },
      "source": [
        "# Train the model\r\n",
        "\r\n",
        "If a previous checkpoint exists, continue training.\r\n",
        "\r\n",
        "Otherwise, train from scratch or do transfer learning from a pretrained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOftFoyiDU3s"
      },
      "source": [
        "outdir = output_path + dataset_name + '/'\n",
        "\n",
        "args = ''\n",
        "if transfer_from:     # train from scratch\n",
        "  network_pkls = glob.glob(os.path.join(outdir.replace('\\ ',' '), '*%s*' % dataset_name, 'network-*.pkl'))\n",
        "  if network_pkls:\n",
        "    resume_from = sorted(network_pkls)[-1].replace(' ','\\ ')\n",
        "    nkimg = int(resume_from[-10:-4])\n",
        "    args += ' --nkimg=%i' % nkimg\n",
        "  else:\n",
        "    resume_from = transfer_from\n",
        "  args += ' --resume=%s' % resume_from\n",
        "  print('Resuming training from %s' % resume_from)\n",
        "\n",
        "args += ' --outdir %s' % outdir\n",
        "args += ' --snap=%i' % snapshot_count\n",
        "args += ' --imgsnap=%i' % imgsnapshot_count\n",
        "args += ' --cfg=11gb-gpu'\n",
        "args += ' --data=./datasets/%s' % dataset_name\n",
        "args += ' --augpipe=bgcfnc' # was default = bgc\n",
        "args += ' --mirror=%s' % str(mirroredX)\n",
        "args += ' --mirrory=%s' % str(mirroredY)\n",
        "args += ' --metrics=None'\n",
        "\n",
        "!python train.py {args}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}